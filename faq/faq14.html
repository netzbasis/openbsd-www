<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>

<!-- If you make edits to any FAQ documents, please start each sentence
     on a new line, and try to keep the general formatting consistent
     with the rest of the pages -->

<title>14 - Disk Setup</title>
<meta name= "description"       content="OpenBSD FAQ 14 - Disk Setup">
<meta name= "copyright"         content="This document copyright 1998-2016
                                         by OpenBSD.">
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<link rel="canonical" href="http://www.openbsd.org/faq/faq14.html">
</head>

<body bgcolor= "#ffffff" text= "#000000">

<a href="../index.html">
<img alt="[OpenBSD]" height=30 width=141 src="../images/smalltitle.gif" border="0">
</a>
<p>
<a href= "index.html">[FAQ Index]</a>
<a href= "faq13.html">[To Section 13 - Multimedia]</a>
<a href= "faq15.html">[To Section 15 - Packages and Ports]</a>

<h1><font color="#e00000">14 - Disk Setup</font></h1><hr>

<h3>Table of Contents</h3>

<ul>
<li><a href="#intro"           >14.1 - Disks and partitions</a>
<li><a href="#fdisk"           >14.2 - Using OpenBSD's fdisk(8)</a>
<li><a href="#disklabel"       >14.3 - Using OpenBSD's disklabel(8)</a>
<li><a href="#BootAmd64"       >14.4 - How does OpenBSD/amd64 boot?</a>
<li><a href="#SoftUpdates"     >14.5 - Soft updates</a>
<li><a href="#altroot"         >14.6 - Duplicating your root partition:
                                <tt>/altroot</tt></a>
<li><a href="#MountImage"      >14.7 - Mounting disk images in OpenBSD</a>
<li><a href="#NegSpace"        >14.8 - Why does df(1) tell me
                                I have over 100% of my disk used?</a>
<li><a href="#softraid"        >14.9 - How do I use softraid?</a>
  <ul>
  <li><a href="#softraidDI"    >14.9.1 - Installing to a mirror</a>
  <li><a href="#softraidFDE"   >14.9.2 - Full disk encryption</a>
  <li><a href="#softraidCrypto">14.9.3 - Encrypting external disks</a>
  <li><a href="#softraidDR"    >14.9.4 - Disaster recovery</a>
  <li><a href="#softraidNotes" >14.9.5 - Softraid notes</a>
  </ul>
<li><a href="#LargeDrive"      >14.10 - What are the issues regarding large
                                drives with OpenBSD?</a>
<li><a href="#Backup"          >14.11 - Preparing for disaster: backing up
                                and restoring from tape</a>
<li><a href="#foreignfs"       >14.12 - Can I access data on filesystems other
                                than FFS?</a>
</ul>
<hr>

<h2 id="intro">14.1 - Disks and partitions</h2>

The details of setting up disks in OpenBSD vary between platforms, so
you should read the installation instructions in the
<tt>INSTALL.&lt;arch&gt;</tt> file for your
<a href="../plat.html">platform</a>
to determine the specifics for your system.

<h3>Drive identification</h3>

OpenBSD handles mass storage with two drivers on most platforms,
depending upon the normal command set that kind of device supports:

<ul>
  <li><a href="http://www.openbsd.org/cgi-bin/man.cgi?query=wd">wd(4)</a>:
    IDE-like disks: IDE, SATA, MFM or ESDI disks, or a flash device
    with an appropriate adapter, attached to a
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=wdc">wdc(4)</a>
    or
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=pciide">pciide(4)</a>
    interface.
  <li><a href="http://www.openbsd.org/cgi-bin/man.cgi?query=sd">sd(4)</a>:
    SCSI-like disks:
    Devices that utilize SCSI commands, USB disks, SATA disks attached to an
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=ahci">ahci(4)</a>
    interface, and disk arrays attached to a RAID controller.
</ul>

The first drive of a particular type identified by OpenBSD will be
drive <tt>0</tt>, the second will be <tt>1</tt>, etc.
So, the first IDE-like disk will be <tt>wd0</tt>, the third SCSI-like disk will
be <tt>sd2</tt>.
If you have two SCSI-like drives and three IDE-like drives on a system,
you would have <tt>sd0</tt>, <tt>sd1</tt>, <tt>wd0</tt>, <tt>wd1</tt> and
<tt>wd2</tt> on that machine.
The order is based on the order they are found during hardware discovery
at boot.
There are a few key points to keep in mind:

<ul>
  <li>
    Drives may not be numbered in the same order as your boot ROM
    attempts to boot them (i.e., your system may attempt to boot what OpenBSD
    identifies as <tt>wd2</tt> or <tt>sd1</tt>).
    Sometimes you may be able to change this, sometimes not.
  <li>Removing or adding a disk may impact the identity of other drives on
    the system.
</ul>

<h3>Partitioning</h3>

Due to historical reasons, the term "partition" is regularly used for
two different things in OpenBSD:

<ul>
  <li>
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
    disklabel(8)</a> partitions, often called filesystem partitions.
  <li>
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
    partitions, often called Master Boot Record (MBR) partitions.
</ul>

All OpenBSD platforms use disklabel(8) as the primary way to manage
OpenBSD filesystem partitions.
Some platforms also require using fdisk(8) to manage MBR partitions.
On the platforms that use them, one fdisk partition is used
to hold all of the OpenBSD file systems.
This partition is then sliced up into 16 disklabel partitions,
labeled <tt>a</tt> through <tt>p</tt>.
A few of these are special:

<ul>
  <li><tt>a</tt>:
    On the boot disk, the <tt>a</tt> partition is your root partition.
  <li><tt>b</tt>:
    On the boot disk, the <tt>b</tt> partition is automatically used
    as a swap partition.
  <li><tt>c</tt>:
    On all disks, the <tt>c</tt> partition is the entire disk, from the
    first sector to the last.
</ul>

<h3>Partition identification</h3>

An OpenBSD filesystem is identified by the disk it is on, plus the
disklabel partition on that disk.
So, file systems may be identified by identifiers like <tt>sd0a</tt>
(the <tt>a</tt> partition of the first <tt>sd</tt> device),
<tt>wd2h</tt> (the <tt>h</tt> partition of the third <tt>wd</tt> device),
or <tt>sd1c</tt> (the entire second <tt>sd</tt> device).
The device files would be <tt>/dev/sd0a</tt> for the block device,
<tt>/dev/rsd0a</tt> would be the device file for the raw (character)
device.

<p>
If you put data on <tt>wd2d</tt>, then later remove <tt>wd1</tt>
from the system and reboot, your data is now on <tt>wd1d</tt>, as your old
<tt>wd2</tt> is now <tt>wd1</tt>.
However, a drive's identification won't change after boot, so if
a USB drive is unplugged or fails, it won't change the identification
of other drives until reboot.

<h3 id="DUID">Disklabel Unique Identifiers</h3>

Disks can also be identified by Disklabel Unique Identifiers (DUIDs), a
16 hex digit number, managed by the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=diskmap">diskmap(4)</a>
device.
This number is a random number generated when a disklabel is first created.
These UIDs are persistent -- if you identify your disks this way,
drive <tt>f18e359c8fa2522b</tt> will always be <tt>f18e359c8fa2522b</tt>,
no matter what order or how it is attached.
You can specify partitions on the disk by appending a period and the
partition letter, for example, <tt>f18e359c8fa2522b.d</tt> is the <tt>d</tt>
partition of the disk <tt>f18e359c8fa2522b</tt> and will always refer
to the same chunk of storage, no matter what order the device is attached
to the system, or what kind of interface it is attached to.

<h2 id="fdisk">14.2 - Using OpenBSD's fdisk(8)</h2>

Be sure to check the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
man page.

<p>
fdisk(8) is used on some platforms (i386, amd64, macppc, zaurus and
armish) to create a partition recognized by the system boot ROM, into
which the OpenBSD disklabel partitions can be placed.
Unlike the fdisk-like programs on some other operating systems,
OpenBSD's fdisk(8) assumes you know what you want to do.

<p>
Normally, only one OpenBSD fdisk partition will be placed on a disk.
That partition will be subdivided by <a href="#disklabel">disklabel</a>
into OpenBSD filesystem partitions.

<p>
To just view your partition table using fdisk, use:

<blockquote><pre>
# <b>fdisk sd0</b>
</pre></blockquote>

Which will give an output similar to this:

<blockquote><pre>
Disk: sd0       geometry: 553/255/63 [8883945 Sectors]
Offset: 0       Signature: 0xAA55
         Starting       Ending       LBA Info:
 #: id    C   H  S -    C   H  S [       start:      size   ]
------------------------------------------------------------------------
*0: A6    3   0  1 -  552 254 63 [       48195:     8835750 ] OpenBSD
 1: 12    0   1  1 -    2 254 63 [          63:       48132 ] Compaq Diag.
 2: 00    0   0  0 -    0   0  0 [           0:           0 ] unused
 3: 00    0   0  0 -    0   0  0 [           0:           0 ] unused
</pre></blockquote>

In this example, we are viewing the fdisk output of the first SCSI-like drive.
We can see the OpenBSD partition (id <tt>A6</tt>) and its size.
The <tt>*</tt> tells us that the OpenBSD partition is the bootable partition.

<p>
In the previous example, we just viewed our information.
In order to edit the partition table use the <tt>-e</tt> flag:

<blockquote><pre>
# <b>fdisk -e sd0</b>
Enter 'help' for information
fdisk: 1>
</pre></blockquote>

<h3>fdisk tricks and tips</h3>

<ul>
  <li>
    fdisk(8) offers the ability to specify partitions both in raw sectors
    and in Cylinder/Head/Sector formats.
  <li>
    A totally blank disk will need to have the master boot record's boot code
    written to the disk before it can boot.
    You can use the <tt>reinit</tt> or <tt>update</tt> commands to do this.
  <li>
    If your system has a "maintenance" or "diagnostic" partition, it is
    recommended that you leave it in place or install it <b>before</b>
    installing OpenBSD.
  <li>
    For historical reasons, <tt>q</tt> saves changes and exits the program,
    and <tt>x</tt> exits without saving.
    This is the opposite of what many people are now used to in other
    environments.
    fdisk(8) does not warn before saving the changes, so use with care.
</ul>

<h2 id="disklabel">14.3 - Using OpenBSD's disklabel(8)</h2>

<h3 id="disklabel.1">What is disklabel(8)?</h3>

First, be sure to read the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>
man page.

<p>
The details of setting up disks in OpenBSD varies somewhat between
platforms.
For <a href="../i386.html">i386</a>,
<a href="../amd64.html">amd64</a>,
<a href="../macppc.html">macppc</a>,
<a href="../zaurus.html">zaurus</a>,
and <a href="../armish.html">armish</a>,
disk setup is done in two stages:
First, the OpenBSD slice of the hard disk is defined using fdisk(8),
then that slice is subdivided into OpenBSD partitions using
disklabel(8).

<p>
All OpenBSD platforms, however, use disklabel(8) as the primary way to
manage OpenBSD partitions.
Labels hold certain information about your disk, like your drive
geometry and information about the filesystems on the disk.
The disklabel is then used by the bootstrap program to access the drive and
to know where filesystems are contained on the drive.
You can read more in-depth information about disklabel in the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel&amp;sec=5">
disklabel(5)</a>
man page.

<p>
On some platforms, disklabel helps overcome architecture limitations on
disk partitioning.
For example, on i386, you can have four primary partitions.
With
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>,
you use one of these primary partitions to store all of your OpenBSD partitions,
and you will still have 3 more partitions available for other OSs.

<h3 id="disklabel.2">disklabel(8) during OpenBSD's install</h3>

By default, the installer will allocate disklabels automatically.
For an example of setting up a custom disklabel(8) during install, see the
<a href="faq4.html#Moredisklabel">custom disklabel layout</a> part of the
<a href="faq4.html">installation guide</a>.

<h3>Disklabel basics</h3>

<ul>
  <li><b>Get help:</b>
    In the command-driven mode, hitting <tt>?</tt> will produce a list of
    available commands.
    <tt>M</tt> will show the man page for disklabel(8).
  <li><b>Auto-partitioning:</b>
    New users are encouraged to use the <tt>A</tt> command to auto-create a
    recommended disklabel.
    You can then edit or alter the auto-created label as you need.
  <li><b>Reset to default:</b>
    In some cases, you may wish to completely restart from scratch and
    delete all existing disklabel information.
    The "D" command will reset the label back to default, as if there had
    never been a disklabel on the drive.
  <li><b><tt>q</tt> vs. <tt>x</tt>:</b>
    For historical reasons, while in the command-driven editor mode, <tt>q</tt>
    saves changes and exits the program, and "x" exits without saving.
    This is the opposite of what many people are now used to in other
    environments.
    disklabel(8) does warn before saving the changes, though it will <tt>x</tt>
    quickly and quietly.
</ul>

<h3>Miscellaneous disklabel tidbits</h3>

<ul>
  <li>(fdisk platforms) <b>Leave first track free:</b>
    On platforms using fdisk(8), you should leave the first logical track
    unused, both in disklabel(8) and in fdisk(8).
    For this reason, OpenBSD defaults to starting the first partition at
    block 64.
  <li>(sparc/sparc64) <b>Don't put swap at the very beginning of your disk.</b>
    While Solaris often puts swap at the very beginning of a disk, OpenBSD
    requires the boot partition to be at the beginning of the disk.
  <li><b>Devices without a disklabel:</b>
    If a device does not currently have an OpenBSD disklabel on it but has
    another file system (for example, a disk with a pre-existing FAT32 file
    system), the OpenBSD kernel will "create" one in memory, and that can form
    the basis of a formal OpenBSD disklabel to be stored on disk.
    However, if a disklabel is created and saved to disk, and a non-OpenBSD
    file system is added later, the disklabel will not be automatically
    updated.
    You must do this yourself if you wish OpenBSD to be able to access this
    file system.
    More on this <a href="faq14.html#foreignfsafter">below</a>.
</ul>

<h3>Recovering partitions after deleting the disklabel</h3>

If you have a damaged partition table, there are various things you can attempt
to do to recover it.

<p>
A copy of the disklabel for each disk is saved in <tt>/var/backups</tt> as part
of the daily system maintenance.
Assuming you still have the <tt>/var</tt> partition, you can simply read the
output, and put it back into disklabel.

<p>
In the event that you can no longer see that partition, there are two
options.
Fix enough of the disk so you can see it, or fix enough of the disk so
that you can get your data off.

<p>
The first tool you need is
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=scan_ffs">scan_ffs(8)</a>
which will look through a disk, and try and find partitions.
It will also tell you what information it finds about them.
You can use this information to recreate the disklabel.
If you just want <tt>/var</tt> back, you can recreate the partition for
<tt>/var</tt>, and then recover the backed up label and add the rest
from that.

<p>
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>
will update both the kernel's understanding of the disklabel, and
then attempt to write the label to disk.
Therefore, even if the area of the disk containing the disklabel is
unreadable, you will be able to
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>
it until the next reboot.

<h2 id="BootAmd64">14.4 - How does OpenBSD/amd64 boot?</h2>

Details on the amd64 bootstrapping procedures are given in the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=boot_amd64">
boot_amd64(8)</a>
man page.
There are four key pieces to the boot process:

<ol>
  <li><b>Master Boot Record (MBR) and GUID Partition Table (GPT):</b>
    The
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
    man page contains detailed explanations.
  <li><b>Partition Boot Record (PBR):</b>
    The first-stage boot loader
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=biosboot">
    biosboot(8)</a>
    occupies the first 512 bytes of the OpenBSD partition of the disk
    and is therefore called the PBR.
    It is installed by
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=installboot">
    installboot(8)</a>.
  <li><b>Second Stage Boot Loader <tt>/boot</tt>:</b>
    The
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=boot">boot(8)</a>
    program is loaded by the PBR and has the task of accessing the OpenBSD
    file system through the machine's BIOS.
    It locates and loads the kernel.
  <li><b>Kernel: <tt>/bsd</tt>:</b>
    This is the goal of the boot process, to have the OpenBSD kernel loaded into
    RAM and properly running.
    Once the kernel has loaded, OpenBSD accesses the hardware directly,
    no longer through the BIOS.
</ol>

So, the very start of the boot process could look like this:

<blockquote><pre>
Using drive 0, partition 3.                      <b>&lt;- MBR</b>
Loading....                                      <b>&lt;- PBR</b>
probing: pc0 com0 com1 apm mem[636k 190M a20=on] <b>&lt;- /boot</b>
disk: fd0 hd0+
>> OpenBSD/i386 BOOT 3.26
boot>
booting hd0a:/bsd 4464500+838332 [58+204240+181750]=0x56cfd0
entry point at 0x100120

[ using 386464 bytes of bsd ELF symbol table ]
Copyright (c) 1982, 1986, 1989, 1991, 1993       <b>&lt;- Kernel</b>
        The Regents of the University of California.  All rights reserved.
   ...
</pre></blockquote>

<h2 id="SoftUpdates">14.5 - Soft updates</h2>

Soft updates are based on an idea proposed by
<a href="http://www.ece.cmu.edu/~ganger/papers/CSE-TR-254-95/">Greg Ganger
and Yale Patt</a> and developed for FreeBSD by
<a href="http://www.mckusick.com/softdep/">Kirk McKusick</a>.
Soft updates imposes a partial ordering on the buffer cache
operations which permits the requirement for synchronous writing of
directory entries to be removed from the FFS code.
A large performance increase is seen in diskwriting performance as a result.

<p>
Enabling soft updates must be done with a mount-time option.
When mounting a partition with the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>
utility, you can specify that you wish to have soft updates enabled on
that partition.
Below is a sample
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fstab">fstab(5)</a>
entry that has one partition <tt>sd0a</tt> that we wish to have mounted
with soft updates.

<blockquote><pre>
/dev/sd0a / ffs rw,softdep 1 1
</pre></blockquote>

Note to sparc users: Do not enable soft updates on sun4 or sun4c machines.
These architectures support only a very limited amount of kernel memory and
cannot use this feature.
However, sun4m machines are fine.

<h2 id="altroot">14.6 - Duplicating your root partition: <tt>/altroot</tt></h2>

OpenBSD provides an <tt>/altroot</tt> facility in the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=daily">daily(8)</a>
scripts.
If the environment variable <tt>ROOTBACKUP=1</tt> is set in either
<tt>/etc/daily.local</tt> or root's
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=crontab">crontab(5)</a>,
and a partition is specified in
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fstab">fstab(5)</a>
as mounting to <tt>/altroot</tt> with the mount options of <tt>xx</tt>, every
night the entire contents of the root partition will be duplicated to the
<tt>/altroot</tt> partition.

<p>
Assuming you want to back up yur root partition to the partition specified
by the <a href="faq14.html#DUID">DUID</a> <tt>bfb4775bb8397569.a</tt>,
add the following to <tt>/etc/fstab</tt>

<blockquote><pre>
bfb4775bb8397569.a /altroot ffs xx 0 0
</pre></blockquote>

and set the appropriate environment variable in <tt>/etc/daily.local</tt>:

<blockquote><pre>
# <b>echo ROOTBACKUP=1 >>/etc/daily.local</b>
</pre></blockquote>

As the <tt>/altroot</tt> process will capture your <tt>/etc</tt> directory, this
will make sure any configuration changes there are updated daily.
This is a "disk image" copy done with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=dd">dd(1)</a>
not a file-by-file copy, so your <tt>/altroot</tt> partition should be at least
the same size as your root partition.
Generally, you will want your <tt>/altroot</tt> partition to be on a different
disk that has been configured to be fully bootable should the primary
disk fail.

<h2 id="MountImage">14.7 - Mounting disk images in OpenBSD</h2>

To mount a disk image in OpenBSD you must configure a
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=vnd">vnd(4)</a>
device.
For example, if you have an ISO image located at <tt>/tmp/ISO.image</tt>,
you would take the following steps to mount the image.

<blockquote><pre>
# <b>vnconfig vnd0 /tmp/ISO.image</b>
# <b>mount -t cd9660 /dev/vnd0c /mnt</b>
</pre></blockquote>

Since this is an ISO 9660 image, as used by CDs and DVDs, you must specify
type of <tt>cd9660</tt> when mounting it.

<p>
To unmount the image and unconfigure the vnd(4) device, do:

<blockquote><pre>
# <b>umount /mnt</b>
# <b>vnconfig -u vnd0</b>
</pre></blockquote>

For more information, refer to 
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=vnconfig">vnconfig(8)</a>
and
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>.

<h2 id="NegSpace">14.8 - Why does df(1) tell me I have over 100% of
my disk used?</h2>

People are sometimes surprised to find they have negative available disk space,
or more than 100% of a filesystem in use, as shown by
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=df">df(1)</a>.

<p>
When a filesystem is created with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=newfs">newfs(8)</a>,
some of the available space is held in reserve from normal users.
This provides a margin of error when you accidently fill the disk, and
helps keep disk fragmentation to a minimum.
Default for this is 5% of the disk capacity, so if the root user has
been carelessly filling the disk, you may see up to 105% of the
available capacity in use.

<p>
If the 5% value is not appropriate for you, you can change it with the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=tunefs">tunefs(8)</a>
command.

<h2 id="softraid">14.9 - How do I use softraid?</h2>

The
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=softraid">softraid(4)</a>
subsystem works by emulating a
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=scsibus">scsibus(4)</a>
with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=sd">sd(4)</a>
devices made by combining a number of OpenBSD
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a> partitions into a virtual disk with the desired RAID level,
such as RAID0, RAID1, RAID4, RAID5 or crypto.
Note that only RAID0, RAID1, RAID5 and crypto are fully supported at the moment.
This virtual disk is treated as any other disk, first partitioned with
<a href="#fdisk">fdisk</a> (on fdisk platforms) and then
<a href="#disklabel">disklabels</a> are created as usual.

<h4>Some words on RAID in general:</h4>

<ul>
  <li>
    Before implementing any RAID solution, understand what it will and
    will not do for you.
    It is not a replacement for a good backup strategy.
    It will not keep your system running through every hardware failure.
    It may not keep your system running through a simple disk failure.
    In the case of software RAID, it won't guarantee the ability to boot
    from the surviving drive if your computer could not otherwise do so.
  <li>
    Before going into production, you must understand how you use your
    RAID solution to recover from failures.
    The time to do this is <b>before</b> your system has had a failure event.
    Poorly implemented RAID will often cause more down time than it will
    prevent.
    This is even more true if it has caused you to become complacent on your
    backups or other disaster planning.
  <li>
    The bigger your RAIDed partitions are, the longer it will take to
    recover from an "event."
    In other words, this is an especially bad time to allocate all of your
    cheap 500GB drives just because they are there.
    Remirroring 500GB drives takes a much longer time than mirroring the
    4GB that you actually use.
    One advantage of software mirroring is one can control how much of
    those "huge" drives is actually used in a RAID set.
  <li>
    There is a reflex to try to RAID as much of your system as possible.
    Even hardware which CAN boot from RAIDed drives will often have difficulty
    determining when a drive has failed to avoid booting from it.
    OpenBSD's <a href="#altroot">altroot</a> system can actually be better
    for some applications, as it provides a copy of old configuration
    information in case a change does not work quite as intended.
  <li>
    RAID provides redundancy only for the disk system.
    Many applications need more redundancy than just the disks, and for some
    applications, RAID can be just added complication, rather than a real
    benefit.
    An example of this is a <a href="faq6.html#CARP">CARP'd</a> set of
    firewalls provide complete fail over redundancy.
    In this case, adding RAID (either via hardware or softraid) is just
    added complication.
</ul>

<h3 id="softraidDI">14.9.1 - Installing to a mirror</h3>

The tools to assemble your softraid system are in the basic OpenBSD
install (for adding softraid devices after install), but they are
also available on the CD-ROM and <a href="faq4.html#bsd.rd">bsd.rd</a>
for installing your system to a softraid setup.
This section covers installing OpenBSD to a mirrored pair of hard drives,
and assumes familiarity with the <a href="faq4.html">installation process</a>
and ramdisk kernel.
Disk setup may vary from platform to platform, and
<b>booting from softraid devices isn't supported on all of them</b>.
It's currently only possible to boot from RAID1, RAID5 and crypto volumes
on i386, amd64 and sparc64.

<p>
The installation process will be a little different than the standard
OpenBSD install, as you will want to drop to the shell and create your
softraid(4) drive before doing the install.
Once the softraid(4) disk is created, you will perform the install relatively
normally, placing the partitions you wish to be RAIDed on the newly
configured drive.
If it sounds confusing at first, don't worry.
All the steps will be explained in detail.

<p>
The install kernel only has the <tt>/dev</tt> entries for one
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=wd">wd(4)</a>
device and one
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=sd">sd(4)</a>
device on boot, so you will need to manually create more disk devices
if your desired softraid setup requires them.

This process is normally done automatically by the installer, but you
haven't yet run the installer, and you will be adding a disk that didn't
exist at boot.
For example, if we needed to support a second wd(4) device for a mirrored
setup, you could do the following from the shell prompt:

<blockquote><pre>
Welcome to the OpenBSD/amd64 X.X installation program.
(I)nstall, (U)pgrade, (A)utoinstall or (S)hell? <b>s</b>
# <b>cd /dev</b>
# <b>sh MAKEDEV wd1</b>
</pre></blockquote>

You now have full support for the <tt>wd0</tt> and <tt>wd1</tt> devices.

<p>
Next, we'll initialize the disks with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
and create the softraid partition with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>.
An "a" partition will be made on both of the drives for the new RAID device.

<blockquote><pre>
# <b>fdisk -iy wd0</b>
Writing MBR at offset 0.
# <b>fdisk -iy wd1</b>
Writing MBR at offset 0.
# <b>disklabel -E wd0</b>
Label editor (enter '?' for help at any prompt)
> <b>a a</b>
offset: [2104515]
size: [39825135] <b>*</b>
FS type: [4.2BSD] <b>RAID</b>
> <b>w</b>
> <b>q</b>
No label changes.
</pre></blockquote>

You'll notice that we initialized both disks, but only created a partition
layout on the first drive.
That's because you can easily import the drive's configuration directly with the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a> command.

<blockquote><pre>
# <b>disklabel wd0 > layout</b>
# <b>disklabel -R wd1 layout</b>
# <b>rm layout</b>
</pre></blockquote>

The "layout" file in this example can be named anything.

<p>
Next, create the mirror with the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=bioctl">bioctl(8)</a>
command.

<blockquote><pre>
# <b>bioctl -c 1 -l /dev/wd0a,/dev/wd1a softraid0</b>
</pre></blockquote>

Note that if you are creating multiple RAID devices, either on one disk
or on multiple devices, you're always going to be using the <tt>softraid0</tt>
virtual disk interface driver.
You won't be using "softraid1" or others.
The "softraid0" there is a virtual RAID controller, and you can hang many
virtual disks off this controller.

<p>
The new pseudo-disk device will show up as <tt>sd0</tt> here, assuming there
are no other sd(4) devices on your system.
This device will now show on the system console and dmesg as a newly
installed device:

<blockquote><pre>
scsibus1 at softraid0: 1 targets
sd0 at scsibus2 targ 0 lun 0: &lt;OPENBSD, SR RAID 1, 005&gt; SCSI2 0/direct fixed
sd0: 10244MB, 512 bytes/sec, 20980362 sec total
</pre></blockquote>

This shows that we now have a new SCSI bus and a new disk, <tt>sd0</tt>.
This volume will be automatically detected and assembled from this point
onwards when the system boots.

<p>
Because the new device probably has a lot of garbage where you expect
a master boot record and disklabel, zeroing the first chunk of it is
highly recommended.
Be <b>very careful</b> with this command; issuing it on the wrong device
could lead to a very bad day.
This assumes that the new softraid device was created as <tt>sd0</tt>.

<blockquote><pre>
# <b>dd if=/dev/zero of=/dev/rsd0c bs=1m count=1</b>
</pre></blockquote>

You are now ready to install OpenBSD on your system.
Perform the install as normal by invoking "install" or "exit" at the boot
media console.
Create all the partitions on your new softraid disk (<tt>sd0</tt> in our
example here) that should be there, rather than on <tt>wd0</tt> or <tt>wd1</tt>
(the non-RAID disks).

<p>
Now you can reboot your system and, if you have done things properly, it
will automatically assemble your RAID set and mount the appropriate
partitions.

<p>
To check on the status of your mirror, issue the following command:

<blockquote><pre>
# <b>bioctl sd0</b>
</pre></blockquote>

A nightly cron job to check the status might also be a good idea.

<h3 id="softraidFDE">14.9.2 - Full disk encryption</h3>

Much like RAID, full disk encryption in OpenBSD is handled by the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=softraid">softraid(4)</a>
subsystem and
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=bioctl">bioctl(8)</a>
command.
This section covers installing OpenBSD to a single encrypted disk, and is a
very similar process to the previous one.

<p>
Select (S)hell at the initial prompt.

<blockquote><pre>
Welcome to the OpenBSD/amd64 X.X installation program.
(I)nstall, (U)pgrade, (A)utoinstall or (S)hell? <b>s</b>
</pre></blockquote>

From here, you'll be given a shell within the live environment to manipulate
the disks.
For this example, we will install to the <tt>wd0</tt> SATA drive, erasing all
of its previous contents.
You may want to write random data to the drive first with something like the
following:

<blockquote><pre>
# <b>dd if=/dev/random of=/dev/rwd0c bs=1m</b>
</pre></blockquote>

This can be a very time-consuming process, depending on the speed of your
CPU and disk, as well as the size of the disk.
If you don't write random data to the whole device, it may be possible for an
adversary to deduce how much space is actually being used.

<p>
Next, we'll initialize the disk with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
and create the softraid partition with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>.

<blockquote><pre>
# <b>fdisk -iy wd0</b>
Writing MBR at offset 0.
# <b>disklabel -E wd0</b>
Label editor (enter '?' for help at any prompt)
> <b>a a</b>
offset: [2104515]
size: [39825135] <b>*</b>
FS type: [4.2BSD] <b>RAID</b>
> <b>w</b>
> <b>q</b>
No label changes.
</pre></blockquote>

We'll use the entire the disk, but note that the encrypted device can be
split up into multiple mountpoints as if it were a regular hard drive.
Now it's time to build the encrypted device on our "a" partition.

<blockquote><pre>
# <b>bioctl -c C -l /dev/wd0a softraid0</b>
New passphrase:
Re-type passphrase:
sd0 at scsibus2 targ 1 lun 0: &lt;OPENBSD, SR CRYPTO, 005&gt; SCSI2 0/direct fixed
sd0: 19445MB, 512 bytes/sector, 39824607 sectors
softraid0: CRYPTO volume attached as sd0
</pre></blockquote>

All data written to <tt>sd0</tt> will now be encrypted (with AES in XTS mode)
by default.

<p>
As in the previous example, we'll overwrite the first megabyte of our new
pseudo-device.

<blockquote><pre>
# <b>dd if=/dev/zero of=/dev/rsd0c bs=1m count=1</b>
</pre></blockquote>

Type <tt>exit</tt> to return to the main installer, then choose this new
device as the one for your installation.

<blockquote><pre>
[...]
Available disks are: wd0 sd0.
Which disk is the root disk? ('?' for details) [wd0] <b>sd0</b>
</pre></blockquote>

You will be prompted for the passphrase on startup, but all other operations
should be handled transparently.

<h3 id="softraidCrypto">14.9.3 - Encrypting external disks</h3>

As we just illustrated, cryptographic softraid(4) volumes are set up rather
simply.
This section explains how you might do so for an external USB flash drive,
but can be applied to any disk device.
If you already read the section on full disk encryption, this should be very
familiar.
An outline of the steps is as follows:

<ul>
  <li>Overwrite the drive's contents with random data
  <li>Create the desired RAID-type partition with disklabel(8)
  <li>Encrypt the drive (note that the initial creation of the container and
    attaching the container are done with the same bioctl(8) command)
  <li>Zero the first megabyte of the new psuedo-partition
  <li>Create a filesystem on the pseudo-device with
  <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=newfs">newfs(8)</a>
  <li>Unlock and
  <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>
    the new pseudo-device
  <li>Access the files as needed
  <li>Unmount the drive and detach the encrypted container
</ul>

A quick example runthrough of the steps follows, with <tt>sd0</tt> being
the USB drive.

<blockquote><pre>
# <b>dd if=/dev/random of=/dev/rsd0c bs=1m</b>
# <b>fdisk -iy sd0</b>
# <b>disklabel -E sd0</b> (create an "a" partition, see above for more info)
# <b>bioctl -c C -l /dev/sd0a softraid0</b>
New passphrase:
Re-type passphrase:
softraid0: CRYPTO volume attached as sd1
# <b>dd if=/dev/zero of=/dev/rsd1c bs=1m count=1</b>
# <b>disklabel -E sd1</b> (create an "i" partition, see above for more info)
# <b>newfs /dev/sd1i</b>
# <b>mkdir -p /mnt/secretstuff</b>
# <b>mount /dev/sd0i /mnt/secretstuff</b>
# <b>mv planstotakeovertheworld.txt /mnt/secretstuff/</b>
# <b>umount /mnt/secretstuff</b>
# <b>bioctl -d sd1</b>
</pre></blockquote>

Next time you need to access the drive, simply use bioctl(8) to attach it
and then repeat the last four commands as needed.

<p>
The man page for this looks a little scary, as the <tt>-d</tt> command is
described as "deleting" the volume.
In the case of crypto, however, it just deactivates encrypted volume so it
can't be accessed until it is activated again with the passphrase.

<p>
Many other options are available with softraid, and new features are
being added and improvements made, so do consult the aforementioned man
pages for detailed information.

<h4>I forgot my passphrase!</h4>

Sorry.
This is real encryption, there's not a back door or magic unlocking
tool.
If you lose your passphrase, your data on your softraid crypto volume
will be unusable.

<h3 id="softraidDR">14.9.4 - Disaster recovery</h3>

This is the section you want to skip over, but don't.
This is the reason for RAID -- if disks never failed, you wouldn't add
the complexity of RAID to your system!
Unfortunately, as failures are very difficult to list comprehensively,
there is a strong probability that the event you experience won't be
described exactly here, but if you take the time to understand the
strategies here, and the WHY, hopefully you can use them to recover
from whatever situations come your way.

<p>
Keep in mind, failures are often not simple.
The author of this article had a drive in a hardware RAID solution develop
a short across the power feed, which in addition to the drive itself,
also required replacing the power supply, the RAID enclosure and a power
supply on a second computer he used to verify the drive was actually
dead, and the data from backup as he didn't properly configure the
replacement enclosure.

<p>
The steps needed for system recovery can be performed in
<a href="faq8.html#LostPW">single user mode</a>, or from the
<a href="faq4.html#bsd.rd">install kernel (bsd.rd)</a>.

<p>
If you plan on practicing softraid recovery (and we <b>highly</b> suggest you
do so!), you may find it helpful to zero a drive you remove from the
array before you attempt to return it to the array.
Not only does this more accurately simulate replacing the drive with a
new one, it will avoid the confusion that can result when the system
detects the remains of a softraid array.

<p>
Recovery from a failure will often be a two-stage event -- the first
stage is bringing the system back up to a running state, the second
stage is to rebuild the failed array.
The two stages may be separated by some time if you don't have a
replacement drive handy.

<h4>Recovery from drive failure: secondary</h4>

This is relatively easy.
You may have to remove the failed disk to get the system back up.

<p>
When you are ready to repair the system, you will replace the failed
drive, create the RAID and other disklabel partitions, then rebuild the
mirror.
Assuming your RAID volume is <tt>sd0</tt>, and you are replacing the
failed device with <tt>wd1m</tt>, the following process should work:

<ul>
  <li>Boot the system back up.
  <li>Create appropriate partitions on your new drive
  <li>Rebuild your RAID partition and reboot:
</ul>

<blockquote><pre>
# <b>bioctl -R /dev/wd1m sd0</b>
# <b>reboot</b>
</pre></blockquote>

<h4>Recovery from drive failure: primary</h4>

Many PC-like computers can not boot from a second drive if the primary
drive has failed, but still attached unless it is so dead it isn't
detected.
Many can not boot from a drive that isn't the "primary", even if there
is no other drive.

<p>
In general, if your primary drive fails, you will have to remove it, and
in many cases "promote" your secondary drive to primary configuration
before the system will boot.
This may involve re-jumpering the disk, plugging the disk into another
port or some other variation.
Of course, what is on the secondary disk has to not only include your RAID
partition, but also has to be functionally bootable.

<p>
Once you have the system back up on the secondary disk and a new
disk in place, you rebuild as above.

<h4>Recovery from "shuffling" your disks</h4>

What if you have four disks in your system, say, sd0, sd1, sd2, and sd3,
and for reasons of hardware replacement or upgrade, you end up with the
drives out of the machine, and lose track of which was which?

<p>
Fortunately, softraid handles this very well, it considers the disks
"roaming," but will successfully rebuild your arrays.
However, the boot disk in the machine has to be bootable, and if you
just made changes in the root partition before doing this, you probably
want to be sure you didn't boot from your altroot partition by mistake.

<h3 id="softraidNotes">14.9.5 - Softraid notes</h3>

<h4>Complications when other sd(4) disks exist</h4>

Softraid disks are assembled <b>after</b> all other IDE, SATA, SAS and
SCSI disks are attached.
As a result, if the number of sd(4) devices changes (either by adding
or removing devices -- or if a device fails), the identifier of the
softraid disk will change.
For this reason, it's important to use <a href="faq14.html#DUID">DUIDs</a>
(Disklabel Unique Identifiers) rather than drive names in your
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fstab">fstab(5)</a> file.

<h4>Three disk RAID1?</h4>

Softraid supports RAID1 with more than two "chunks," and the man page
examples show a three-disk RAID1 configuration.
RAID1 simply duplicates the data across all the chunks of storage.
Two gives full redundancy, three gives additional fault tolerance.
The advantage of RAID1 with three (or more) disks/chunks is that, in
event of one disk failure, you still have complete redundancy.
Think of it as a hot spare that doesn't need time to rebuild!

<h2 id="LargeDrive">14.10 - What are the issues regarding large drives with
OpenBSD?</h2>

OpenBSD supports both FFS and FFS2 file systems, also known as UFS and UFS2.
Before looking at the limits of each system, we need to look at some
more general system limits.

<p>
Of course, the ability of file system and the abilities of particular
hardware are two different things.
A newer 250G IDE hard disk may have issues on older (pre >137G
standards) interfaces (though for the most part, they work just fine),
and some very old SCSI adapters have been seen to
have problems with more modern drives, and some older BIOSs will hang
when they encounter a modern sized hard disk.
You must respect the abilities of your hardware and boot code, of
course.

<h3>Partition size and location limitations</h3>

Unfortunately, the full ability of the OS isn't available until <b>after</b>
the OS has been loaded into memory.
The boot process has to utilize (and is thus limited by) the system's boot ROM.

<p>
For this reason, the entire /bsd file (the kernel) must be located on
the disk within the boot ROM addressable area.
This means that on some older i386 systems, the root partition must be
completely within the first 504M, but newer computers may have limits of
2G, 8G, 32G, 128G or more.
It is worth noting that many relatively new computers which support
larger than 128G drives actually have BIOS limitations of booting
only from within the first 128G.
You can use these systems with large drives, but your root partition
must be within the space supported by the boot ROM.

<p>
Note that it is possible to install a 40G drive on an old 486 and load
OpenBSD on it as one huge partition, and think you have successfully
violated the above rule.
However, it might come back to haunt you in a most unpleasant way:

<ul>
  <li>You install on the 40G / partition.
    It works, because the base OS and all its files (including /bsd) are within
    the first 504M.
  <li>You use the system, and end up with more than 504M of files on it.
  <li>You upgrade, and copy your new /bsd over the old one.
  <li>You reboot.
  <li>You get a message such as "ERR M" or other problems on boot.
</ul>

Why?
Because when you copied "over" the new <tt>/bsd</tt> file, it didn't
overwrite the old one, it got relocated to a new location on the
disk, probably outside the 504M range the BIOS supported.
The boot loader was unable to fetch the file <tt>/bsd</tt>, and the system hung.

<p>
To get OpenBSD to boot, the boot loaders (biosboot(8) and <tt>/boot</tt>
in the case of i386/amd64) and the kernel (<tt>/bsd</tt>) must be within the
boot ROM's supported range, and within their own abilities.
To play it safe, the rule is simple:

<blockquote>
<b>The entire root partition must be within the computer's BIOS
(or boot ROM) addressable space.</b>
</blockquote>

Some non-i386 users think they are immune to this, however most platforms
have some kind of boot ROM limitation on disk size.
Finding out for sure what the limit is, however, can be difficult.

<p>
This is another good reason to <a href="faq4.html#Partitioning">partition
your hard disk</a>, rather than using one large partition.

<h3>fsck(8) time and memory requirements</h3>

Another consideration with large file systems is the time and memory
required to
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fsck">fsck(8)</a>
the file system after a crash or power interruption.
One should not put a 120G file system on a system with 32M of RAM and
expect it to successfully fsck(8) after a crash.
A rough guideline is the system should have at least 1M of available
memory for every 1G of disk space to successfully fsck the disk.
Swap can be used here, but at a very significant performance penalty,
so severe that it is usually unacceptable, except in special cases.

<p>
The time required to fsck the drive may become a problem as the file
system size expands, but you only have to fsck the disk space that is
actually allocated to mounted filesystems.
This is another reason NOT to allocate all your disk space Just Because
It Is There.
Keeping file systems mounted RO or not mounted helps keep them from
needing to be fsck(8)ed after tripping over the power cord.
Reducing the number of inodes (using the -i option of newfs) can also
improve fsck time -- assuming you really don't need them.

<p>
Don't forget that if you have multiple disks on the system, they could
all end up being fsck(8)ed after a crash at the same time, so they could
require more RAM than a single disk.

<h3>FFS vs. FFS2</h3>

Using FFS, OpenBSD supports an individual file system of up to
2<sup>31</sup>-1, or 2,147,483,647 blocks, and as each block is 512
bytes, that's a tiny amount less than 1T.
FFS2 is capable of much larger file systems, though other limits will be
reached long before the file system limits will be reached.

<p>
The boot/installation kernels <i>only support FFS</i>, not FFS2, so key
system partitions (<tt>/, /usr, /var, /tmp</tt>) should not be FFS2, or
severe maintenance problems can arise (there should be no reason for
those partitions to be that large, anyway).
For this reason, very large partitions should only be used for
"non-system" partitions, for example, <tt>/home, /var/www/,
/bigarray</tt>, etc.

<p>
Note that not all controllers and drivers support large disks.
For example,
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=ami">ami(4)</a>
has a limit of 2TB per logical volume.
Always be aware of what was available when a controller or interface was
manufactured, and don't just rely on "the connectors fit".

<h3>Disks larger than 2TB</h3>

The MBR system used on PCs only directly understands disks up to 2TB in
size.
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
will show disks larger than 2TB as only 2TB.
This does not in any way hinder OpenBSD's ability to utilize larger
disks, as the MBR is used only to bootstrap the OS.
Once the OS is
running, the file systems are defined by the disklabel, which does not
have a 2TB limit.

<p>
To use a disk larger than 2TB, create an OpenBSD partition on the disk
using fdisk, whatever size fdisk will let you.
When you label the disk with
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=disklabel">
disklabel(8)</a>,
use the "b" option to set the OpenBSD boundaries (which defaulted to
the size of the OpenBSD fdisk partition) to cover the entire disk.
Now you can create your partitions as you wish.
You must still respect the abilities of your BIOS, which will have the
limitation of only understanding fdisk partitions, so your 'a'
partition should be entirely within the fdisk-managed part of the disk,
in addition to any BIOS limitations.

<h2 id="Backup">14.11 - Preparing for disaster: backing up and restoring
from tape</h2>

<h3>Introduction:</h3>

If you plan on running what might be called a production server, it is
advisable to have some form of backup in the event one of your fixed
disk drives fails, or the data is otherwise lost.

<p>
This information will assist you in using the standard
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=dump">dump(8)</a>
and
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=restore">restore(8)</a>
utilities provided with OpenBSD.
More advanced backup utilities, such as
"<a href="http://www.bacula.org/">Bacula</a>"
are available through
<a href="faq15.html#PkgMgmt">packages</a> for backing up multiple servers to
disk and tape.

<h3>Backing up to tape:</h3>

Backing up to tape requires knowledge of where your file systems are mounted.
You can determine how your filesystems are mounted using the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>
command at your shell prompt.
You should get output similar to this:

<blockquote><pre>
# <b>mount</b>
/dev/sd0a on / type ffs (local)
/dev/sd0h on /usr type ffs (local)
</pre></blockquote>

In this example, the root (<tt>/</tt>) filesystem resides physically on sd0a
which indicates a SCSI-like fixed disk 0, partition a.
The <tt>/usr</tt> filesystem resides on sd0h, which indicates SCSI-like
fixed disk 0, partition h.

<p>
Another example of a more advanced mount table might be:

<blockquote><pre>
# <b>mount</b>
/dev/sd0a on / type ffs (local)
/dev/sd0d on /var type ffs (local)
/dev/sd0e on /home type ffs (local)
/dev/sd0h on /usr type ffs (local)
</pre></blockquote>

In this more advanced example, the root (<tt>/</tt>) filesystem resides
physically on sd0a.
The <tt>/var</tt> filesystem resides on sd0d, the <tt>/home</tt>
filesystem on sd0e and finally <tt>/usr</tt> on sd0h.

<p>
To backup your machine, you will need to feed dump the name of each fixed disk
partition.
Here is an example of the commands needed to backup the simpler mount table
listed above:

<blockquote><pre>
# <b>/sbin/dump -0au -f /dev/nrst0 /dev/rsd0a</b>
# <b>/sbin/dump -0au -f /dev/nrst0 /dev/rsd0h</b>
# <b>mt -f /dev/rst0 rewind  </b>
</pre></blockquote>

For the more advanced mount table example, you would use something
similar to:

<blockquote><pre>
# <b>dump -0au -f /dev/nrst0 /dev/rsd0a</b>
# <b>dump -0au -f /dev/nrst0 /dev/rsd0d</b>
# <b>dump -0au -f /dev/nrst0 /dev/rsd0e</b>
# <b>dump -0au -f /dev/nrst0 /dev/rsd0h  </b>
# <b>mt -f /dev/rst0 rewind  </b>
</pre></blockquote>

You can review the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=dump">dump(8)</a>
man page to learn exactly what each command line switch does.
Here is a brief description of the parameters used above:

<ul>
  <li><b>0</b> - Perform a level 0 dump, get everything
  <li><b>a</b> - Attempt to automatically determine tape media length
  <li><b>u</b> - Update the file <tt>/etc/dumpdates</tt> to indicate when
    backup was last performed
  <li><b>f</b> - Which tape device to use (/dev/nrst0 in this case)
</ul>

Finally which partition to backup (/dev/rsd0a, etc.)

<p>
The
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mt">mt(1)</a>
command is used at the end to rewind the drive.
Review the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mt">mt(1)</a>
man page for more options (such as eject).

<p>
If you are unsure of your tape device name, use dmesg to locate it.
An example tape drive entry in dmesg might appear similar to:

<blockquote><pre>
st0 at scsibus0 targ 5 lun 0: &lt;ARCHIVE, Python 28388-XXX, 5.28&gt;
</pre></blockquote>

You may have noticed that when backing up, the tape drive is accessed as
device name <tt>nrst0</tt> instead of the <tt>st0</tt> name that is seen in
dmesg.
When you access <tt>st0</tt> as <tt>nrst0</tt> you are accessing the same
physical tape drive but telling the drive to not rewind at the end of the job
and access the device in raw mode.
To back up multiple file systems to a single tape, be sure you use the
non-rewind device.
If you use a rewind device (<tt>rst0</tt>) to back up multiple file systems,
you'll end up overwriting the prior filesystem with the next one dump tries
to write to tape.
You can find a more elaborate description of various tape drive devices in the
dump man page.

<p>
If you wanted to write a small script called "backup", it might look
something like this:

<blockquote><pre>
echo "  Starting Full Backup..."
dump -0au -f /dev/nrst0 /dev/rsd0a
dump -0au -f /dev/nrst0 /dev/rsd0d
dump -0au -f /dev/nrst0 /dev/rsd0e
dump -0au -f /dev/nrst0 /dev/rsd0h
echo
echo -n "  Rewinding Drive, Please wait..."
mt -f /dev/rst0 rewind
echo "Done."
echo
</pre></blockquote>

If scheduled nightly backups are desired,
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=cron">cron(8)</a>
could be used to launch your backup script automatically.

<p>
It will also be helpful to document (on a scrap of paper) how large each
file system needs to be.
You can use <tt>df -h</tt> to determine how much space each partition is
currently using.
This will be handy when the drive fails and you need to recreate your
partition table on the new drive.

<p>
Restoring your data will also help reduce fragmentation.
To ensure you get all files, the best way of backing up is rebooting your
system in single user mode.
File systems do not need to be mounted to be backed up.
Don't forget to mount root (/) r/w after rebooting in single user mode or
your dump will fail when trying to write out dumpdates.
Enter <tt>bsd -s</tt> at the boot> prompt for single user mode.

<h3>Viewing the contents of a dump tape:</h3>

After you've backed up your file systems for the first time, it would be
a good idea to briefly test your tape and be sure the data on it is as
you expect it should be.

<p>
You can use the following example to review a catalog of files on a dump
tape:

<blockquote><pre>
# <b>restore -tvs 1 -f /dev/rst0</b>
</pre></blockquote>

This will cause a list of files that exist on the 1st partition of the
dump tape to be listed.
Following along from the above examples, 1 would be your root file system.

<p>
To see what resides on the 2nd tape partition and send the output to a
file, you would use a command similar to:

<blockquote><pre>
# <b>restore -tvs 2 -f /dev/rst0 > /home/me/list.txt</b>
</pre></blockquote>

If you have a mount table like the simple one, 2 would be /usr, if yours
is a more advanced mount table 2 might be /var or another fs.
The sequence number matches the order in which the file systems are written
to tape.

<h3>Restoring from tape:</h3>

The example scenario listed below would be useful if your fixed drive
has failed completely.
In the event you want to restore a single file from tape, review the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=restore">restore(8)</a>
man page and pay attention to the interactive mode instructions.

<p>
If you have prepared properly, replacing a disk and restoring your data
from tape can be a very quick process.
The standard OpenBSD install/boot CD already contains the required restore(8)
utility as well as the binaries required to partition and make your new drive
bootable.
In most cases, a CD and your most recent dump tape is all you'll need to
get back up and running.

<p>
After physically replacing the failed disk drive, the basic steps to
restore your data are as follows:

<ul>
  <li>
    Boot from the OpenBSD install/boot floppy.
    At the menu selection, choose Shell.
    Write protect and insert your most recent back up tape into the drive.

  <li>
    Using the
    <a href="http://www.openbsd.org/cgi-bin/man.cgi?query=fdisk">fdisk(8)</a>
    command, create a primary OpenBSD partition on this newly installed
    drive.
    Example:

    <blockquote><pre>
    # <b>fdisk -e sd0</b>
    </pre></blockquote>

    See <a href="#fdisk">fdisk FAQ</a> for more info.

  <li>
    Using the disklabel command, recreate your OpenBSD partition table
    inside that primary OpenBSD partition you just created with fdisk.
    Example:

    <blockquote><pre>
    # <b>disklabel -E sd0</b>
    </pre></blockquote>

    (Don't forget swap, see <a href="#disklabel">disklabel FAQ</a>
    for more info)

  <li>
    Use the newfs command to build a clean file system on each partition you
    created in the above step.
    Example:

    <blockquote><pre>
    # <b>newfs /dev/rsd0a</b>
    # <b>newfs /dev/rsd0h</b>
    </pre></blockquote>

  <li>
    Mount your newly prepared root (/) file system on /mnt.
    Example:

    <blockquote><pre>
    # <b>mount /dev/sd0a /mnt</b>
    </pre></blockquote>

  <li>
    Change into that mounted root file system and start the restore process.
    Example:

    <blockquote><pre>
    # <b>cd /mnt</b>
    # <b>restore -rs 1 -f /dev/rst0</b>
    </pre></blockquote>

  <li>
    You'll want this new disk to be bootable, use the following to write a
    new MBR to your drive.
    Example:

    <blockquote><pre>
    # <b>fdisk -i sd0</b>
    </pre></blockquote>

  <li>
    In addition to writing a new MBR to the drive, you will need to install
    boot blocks to boot from it.
    The following is a brief example:

    <blockquote><pre>
    # <b>installboot -v -r /mnt sd0</b>
    </pre></blockquote>

  <li>
    Your new root file system on the fixed disk should be ready enough so
    you can boot it and continue restoring the rest of your file systems.
    Since your operating system is not complete yet, be sure you boot back
    up with single user mode.
    At the shell prompt, issue the following commands to unmount and
    halt the system:

    <blockquote><pre>
    # <b>umount /mnt</b>
    # <b>halt</b>
    </pre></blockquote>

  <li>
    Remove the install/boot floppy from the drive and reboot your system.
    At the OpenBSD boot&gt; prompt, issue the following command:

    <blockquote><pre>
    boot> <b>bsd -s</b>
    </pre></blockquote>

    The bsd -s will cause the kernel to be started in single user mode which
    will only require a root (/) file system.

  <li>
    Assuming you performed the above steps correctly and nothing has gone
    wrong, you should end up at a prompt asking you for a shell path or press
    return.
    Press return to use sh.
    Next, you'll want to remount root in r/w mode as opposed to read only.
    Issue the following command:

    <blockquote><pre>
    # <b>mount -u -w /</b>
    </pre></blockquote>

  <li>
    Once you have re-mounted in r/w mode, you can continue restoring your
    other file systems.
    Example:

    <blockquote><pre>
    <i>(simple mount table)</i>
    # <b>mount /dev/sd0h /usr; cd /usr; restore -rs 2 -f /dev/rst0</b>

    <i>(more advanced mount table)</i>
    # <b>mount /dev/sd0d /var; cd /var; restore -rs 2 -f /dev/rst0</b>
    # <b>mount /dev/sd0e /home; cd /home; restore -rs 3 -f /dev/rst0</b>
    # <b>mount /dev/sd0h /usr; cd /usr; restore -rs 4 -f /dev/rst0</b>
    </pre></blockquote>

    You could use "<b>restore rvsf</b>" instead of just rsf to view names of
    objects as they are extracted from the dump set.

  <li>
    Finally after you finish restoring all your other file systems to disk,
    reboot into multiuser mode.
    If everything went as planned, your system will be back to the state it
    was in as of your most recent back up tape and ready to use again.
</ul>

<h2 id="foreignfs">14.12 - Can I access data on filesystems other than FFS?</h2>

Yes.
Start with the
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount">mount(8)</a>
manual which contains examples explaining how to mount some of the
most commonly used filesystems.
A partial list of
<a href="http://www.openbsd.org/cgi-bin/man.cgi?query=mount_&amp;sec=8&amp;apropos=1">
supported file systems</a>
and related commands can be obtained with

<blockquote><pre>
# <b> man -k -s 8 mount</b>
</pre></blockquote>

Note that support may be limited to read-only operation.

<p>
<hr>
<p>
<a href= "index.html">[FAQ Index]</a>
<a href= "faq13.html">[To Section 13 - Multimedia]</a>
<a href= "faq15.html">[To Section 15 - Packages and Ports]</a>
</body>
</html>
